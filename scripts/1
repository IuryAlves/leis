# -*- coding: utf-8 -*-
from lxml import html
import requests,unicodedata,json

# constants
DATA = '../src/data/'
URL_VEREADORES = 'http://www.camarasjc.sp.gov.br/vereadores/'
EXPRESSION_LINK_VEREADORES = '//*[@id="conteudo-principal"]/div[2]/div/div[2]/div/a'
JSON_VEREADORES = DATA + 'vereadores.json'

# to help match the congress page names with the tse json names
def name_corrections(s):
	if(s == u'AMÉLIA NAOMI'):
		return u'AMELIA NAOMI'
	if(s == u'DRA ANGELA'):
		return u'ANGELA GUADAGNIN'
	if(s == u'FERNANDO PETITI DA FARMÁCIA COMUNITÁRIA'):
		return u'PETITI DA FARMÁCIA COMUNITÁRIA'
	if(s == u'LUIZ MOTA'):
		return u'MOTA'
	if(s == u'PROF. CALASANS CAMARGO'):
		return u'PROFESSOR CALASANS CAMARGO'
	if(s == u'ROGÉRIO CYBORG'):
		return u'CYBORG'
	if(s == u'WAGNER BALIEIRO '):
		return u'WAGNER BALIEIRO'
	if(s == u'WILLIS GOULART'):
		return u'WILLIS'
	return s
# open the vereadores files that contains the vereadores data
fileVereadores = open(JSON_VEREADORES)
jsonVereadores = json.loads(fileVereadores.read())
fileVereadores.close()


# open the vereadores page for scraping
page = requests.get(URL_VEREADORES)
tree = html.fromstring(page.content)
linkVereadores = tree.xpath(EXPRESSION_LINK_VEREADORES)

# will read each vereador  URL to open his personal page to download the data  
for link in linkVereadores:
	name = unicode(link.text.upper())
	name = name_corrections(name)
	v_json = None
	for v in jsonVereadores:
		if(v['NOME_URNA_CANDIDATO'] == name or v['NOME_CANDIDATO'] == name):
			v_json = v
	if(v_json is None):
		print 'Not Found: ' + name
	else:
		print 'processing... ' + name
		# TODO open the vereador page and download the info 

# saves the new JSON
#new_json =  json.dumps(jsonVereadores, indent=4, sort_keys=True)
#fileVereadores = open(JSON_VEREADORES, 'w')
#fileVereadores.write(new_json)
#fileVereadores.close()
#/opt/projects/leis/src/assets/images/vereadores

